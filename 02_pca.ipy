# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.8.0
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

# %% [markdown]
# # PCA by gradient descent
# ## Will Townes
#
# This code was originally based on https://gist.github.com/ahwillia/4c10830640d325e0cab978bc18c6263a 
# 
# See also https://www.nxn.se/valent/2017/6/19/approximate-pca-by-mini-batch-sgd-using-tensorflow

# %%
import numpy as np
import tensorflow as tf
from matplotlib import pyplot as plt
from tensorflow.keras import layers
rng = np.random.default_rng()
def mse(Y,U,V):
    return np.mean((Y-U@V.T)**2)

# %% Generate data
N = 100 #number of observations
J = 50 #number of features
L = 5 #number of latent dimensions
U = rng.normal(size=(N,L))
V = rng.normal(size=(J,L))
Y = U @ V.T + rng.normal(scale=.1,size=(N,J))

# %% SVD
svd_Y = np.linalg.svd(Y,full_matrices=False)
U_svd = svd_Y[0][:,:L]*svd_Y[1][:L]
V_svd = svd_Y[2][:L,:].T
mse_svd = mse(Y,U_svd,V_svd)

# %% Global variables and convenience functions
BATCH_SIZE = 29
ADAM_LEARN_RATE = 0.01
NUM_EPOCHS = 500
x = np.array(range(N))
D = tf.data.Dataset.from_tensor_slices((x,Y)).batch(BATCH_SIZE)
optimizer = tf.optimizers.Adam(ADAM_LEARN_RATE)

def postprocess(U,V):
    svd_V = np.linalg.svd(V,full_matrices=False)
    V = svd_V[0]
    U = U @ svd_V[2].T * svd_V[1]
    return U,V


# %% Tensorflow keras
%%time
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(N, L, embeddings_initializer='normal'),
    tf.keras.layers.Dense(units=J,use_bias=True,kernel_initializer='normal')
    ])
model.compile(optimizer, loss='mean_squared_error')
history1 = model.fit(x,Y, epochs=NUM_EPOCHS, verbose=1, batch_size=BATCH_SIZE)
U_k = model.layers[0].embeddings.numpy().squeeze()
V_k = model.layers[1].kernel.numpy().squeeze().T
mse_k = mse(Y,U_k,V_k)
plt.plot()
fig, ax = plt.subplots()
#ax.set_yscale('log')
ax.plot(history1.history['loss'])
ax.axhline(mse_svd,c='red',dashes=[5])
plt.show()


# %% Tensorflow manual
%%time
class MyPCA(tf.Module):
  def __init__(self, data_dim, features_dim, latent_dim, **kwargs):
    super().__init__(**kwargs)
    self.U = tf.Variable(rng.normal(size=(data_dim,latent_dim)), name="factors")
    self.V = tf.Variable(rng.normal(size=(features_dim,latent_dim)), name="loadings")

  def __call__(self,idx):
    U_ss = tf.gather(self.U,idx)
    return tf.linalg.matmul(U_ss,self.V,transpose_b=True)

def loss(target_y, predicted_y):
  return tf.reduce_mean(tf.square(target_y - predicted_y))

#idx_list = np.array_split(range(N), np.ceil(N/BATCH_SIZE))
model = MyPCA(N,J,L)
msg = 'Epoch: {:03d}, loss: {:.3E}'
loss_history = []
for epoch in range(NUM_EPOCHS):
    epoch_loss_avg = tf.keras.metrics.Mean()
    for idx, Yss in D: #iterate through each of the batches
        with tf.GradientTape() as tape:
            current_loss = loss(Yss, model(idx))
        #how to compute gradient for only the slice of U instead of all?
        grads = tape.gradient(current_loss, model.trainable_variables)
        optimizer.apply_gradients(zip(grads, model.trainable_variables))
        epoch_loss_avg.update_state(current_loss)
    loss_history.append(epoch_loss_avg.result())
    if epoch%100==0:
        print(msg.format(epoch,loss_history[epoch]))
# postprocessing        
U_tf,V_tf = postprocess(model.U.numpy(), model.V.numpy())

# for l in range(L): #fix the sign flips
#     if np.sign(U_svd[0,l]) != np.sign(U_tf[0,l]):
#         U_svd[:,l]*= -1
#         V_svd[:,l]*= -1
mse_tf = mse(Y,U_tf,V_tf)
print("MSE for SVD: {:.3E}, MSE for TF: {:.3E}".format(mse_svd,mse_tf))

# %% Tensorflow manual: loss trace plot
plt.plot()
fig, ax = plt.subplots()
ax.set_yscale('log')
ax.axhline(mse_svd,c='red')
ax.plot(loss_history)
plt.xlabel('iteration')
plt.ylabel('loss (MSE)');
plt.show()

# %% Tensorflow manual: compare to SVD
def txflat(x):
    return (x@x.T).flatten()
plt.scatter(txflat(V_svd), txflat(V_tf))
plt.axline((0,0),slope=1,c='red')

# %% Tensorflow manual: compare to SVD
plt.scatter(txflat(U_svd),txflat(U_tf))
plt.axline((0,0),slope=1,c='red')

# %% Tensorflow linear autoencoder
%%time
class LinearAutoencoder(tf.keras.Model):
  def __init__(self, features_dim, latent_dim):
    super(LinearAutoencoder, self).__init__()
    self.latent_dim = latent_dim 
    self.encoder = tf.keras.Sequential([
        layers.Dense(latent_dim,use_bias=True)
    ])
    self.decoder = tf.keras.Sequential([
      layers.Dense(features_dim,use_bias=False)
    ])
  def call(self,x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded

model = LinearAutoencoder(J,L)
model.compile(optimizer=optimizer, loss='mean_squared_error')
history1 = model.fit(Y, Y, epochs=NUM_EPOCHS, verbose=0, batch_size=BATCH_SIZE)
U_ae,V_ae = postprocess(model.encoder(Y).numpy(), model.decoder.layers[0].kernel.numpy().T)
mse_ae = mse(Y,U_ae,V_ae)
print("MSE for SVD: {:.3E}, MSE for TF: {:.3E}, MSE for AE: {:.3E}".format(mse_svd,mse_tf,mse_ae))

# %% Linear Autoencoder vs TF PCA
plt.plot()
fig, ax = plt.subplots()
ax.set_yscale('log')
ax.axhline(mse_svd,c='red')
ax.plot(loss_history)
ax.plot(history1.history['loss'],c='green')
plt.xlabel('iteration')
plt.ylabel('loss (MSE)');
plt.show()

# %% Tensorflow manual: compare to SVD
plt.scatter(txflat(V_svd), txflat(V_ae))
plt.axline((0,0),slope=1,c='red')

# %% Tensorflow manual: compare to SVD
plt.scatter(txflat(U_svd),txflat(U_ae))
plt.axline((0,0),slope=1,c='red')